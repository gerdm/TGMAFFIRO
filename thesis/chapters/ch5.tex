\documentclass[../TGMAFFIRO.tex]{subfiles}

\begin{document}
\section{It\^o's Integral}
Let $\ProbSpace$ a probability space and consider the spaces $L_2\ProbSpace$ and $L_2([a, b]\times\Omega, \mathscr{B}\otimes\salgF)$ with inner product
\begin{equation}
  \innerprod{f}{g} := \int_\Omega\int_0^t f(s) g(s) ds d\Pm = \Exp{\int_0^t f(s)g(s) ds},
\end{equation}


and norm in $L_2([a, b] \times \Omega)$
\begin{equation}
  \norm{f}_{[a, b] \times \Omega} := \sqrt{\innerprod{f}{f}} = \sqrt{\Exp{\int_0^t f(s)g(s) ds}}.
\end{equation}

We want to make sense of
\begin{equation}
  \int_a^bf(t,\omega) \dW[t](\omega).
\end{equation}

Where $W_t$ is a standard Brownian motion and $f$ belongs to a special family of functions denoted by $\Nfam{a}{b}$.

\begin{definition}
	Let $0\leq a\leq b$. Denote $\Nfam{a}{b}$ the family of stochastic process such that
	\begin{enumerate}
		\item $(t, \omega) \to f(t, \omega):[0, \infty]\times\Omega \to \RNums$ is $\borelsalg\times\salgF$ measurable;
		\item $f(t,\omega)$ is $\salgF_t$-adapted; and
		\item $f\in L_2([a,b]\times\Omega)$ i.e. $\int_a^b\int_\Omega f^2 d\Pm dt = \int_a^b\Exp{f^2}dt = \Exp{\int_a^b f^2 dt} < \infty$.
	\end{enumerate}
\end{definition}

\begin{definition}[\textbf{Simple Process}]
	We define the process $f\in \Nfam{a}{b}$ as simple if there exists a partition $\{t_i\}_{i=0}^n$ where $t_0 = a$, $t_n = b$, and $t_i < t_j \ \forall \ i < j$, such that $f$ can be represented as a lineal combination of the form
	\begin{equation}
		f(t) = \sum_{i=0}^{n-1}f(t_i)\ind_{[t_i, t_{i+1}]}(t).
	\end{equation}
\end{definition}

\begin{definition}
	We define the family of processes $f$ in $\Mfam{a}{b}$ that are processes in $\Nfam{a}{b}$ and can be written as simple processes. 
\end{definition}

\begin{definition}
	Let $f\in\Mfam{a}{b}$, we define the It\^o integral of $f$ as
\begin{equation}
	  \int_a^b f(t) dW_t := \sum_{i=0}^{n-1} \DeltaW .
\end{equation}

With $\Delta W_i := W_{t_{i+1}} - W_{t_{i}}$.\\
We will also denote It\^o's integral as $I(f)$ or $\int f$.
\end{definition}

\begin{proposition}
	Let $f$, $g$ $\in \Mfam{0}{t}$ then
	\begin{enumerate}
		\item $I(\alpha f + \beta g) = \alpha I(f) + \beta I(g)$;
		\item $\Exp{I(f)} = 0$; and
		\item $\Var{I(f)} = \Exp{\left(\int_0^t f(s) dW_s\right)^2} = \Exp{\int_0^t f^2(t) dt}$ (It\^o Isometry).
	\end{enumerate}
\end{proposition}

\begin{proof}
	1). Let $f,g\in\Mfam{0}{t}$, and $\alpha, \beta \in\RNums$. Then, we can write $f$ and $g$ as a simple process. Namely,
	\begin{align}
		f(t) = \sum_{i=0}^{n-1}f(t_i)\ind_{i}(t) \text{; and}\\
		g(t) = \sum_{j=0}^{m-1}g(t_j)\ind_{j}(t).
	\end{align}
	\newcommand{\fsimple}{\sum_{i=0}^{n-1}f(t_i)\ind_{i}(t)}
	\newcommand{\gsimple}{\sum_{j=0}^{m-1}g(t_j)\ind_{j}(t)}
	
	Where $\ind_i(t) := \ind_{t_{i}, t_{i+1}}(t)$. We now consider the following
	\begin{align*}
		\int_0^t(\alpha f(s) + \beta g(s))dW_s &= \int_0^t\left(\alpha \fsimple + \beta \gsimple \right) dW_s\\
		&= \sum_{k=0}^{n-1}\left(\alpha \fsimple + \beta \gsimple \right) \DeltaW[j]\\
		&= \alpha\sum_{k=0}^{n-1}\left(\fsimple\right)\Delta W_j + \\
		&\phantom{{}=1}\beta\sum_{k=0}^{n-1}\left(\gsimple\right)\DeltaW[j]\\
		&= \alpha\int_0^t f(s) dW_s + \beta \int_0^t g(s) \dW[s].
	\end{align*}
	
	2) For this next proof, we first note that $\Delta W_i$ is independent of its $\salg$. We can then write
	\begin{align}
		\E[\DeltaW| \salgF_{t_i}] &= \E[\DeltaW] = 0 \text{, and}\\
		\E[\DeltaW^2 | \salgF_{t_i}] &= \E[\DeltaW^2] = \E[\left(W_{t_{i+1}} - W_{t_{i}}\right)^2] = t_{i+1} - t_i.
	\end{align}
	Consider now
	\begin{align*}
	\Exp{f(t_i)\DeltaW} &= \Exp{\Exp{f(t_i)\DeltaW|\salgF_{t_i}}}\\
						&= \Exp{f(t_i)\Exp{\DeltaW|\salgF_{t_i}}}\\
						&= 0.
	\end{align*}
	It follows,
	\begin{align*}
		\Exp{I(f)} &= \Exp{\sum_{i=0}^{n-1}f(t_i)\DeltaW}\\
				   &= \sum_{i=0}^{n-1}\Exp{f(t_i)\DeltaW}\\
				   &= 0.
	\end{align*}
	
	We now consider
	\begin{align}
		\Exp{I(f)^2} &= \Exp{\left(\sum_{i=0}^{n-1} f(t_i) \DeltaW \right)^2}\label{eq:itois1} \\
					 &= \Exp{\sum_{i=0}^{n-1}f^2(t_i)\left(\DeltaW\right)^2 +  2\sum_{i<j}f(t_i)f(t_j) \DeltaW\DeltaW[j]}\nonumber \\
					 &= \sum_{i=0}^{n-1}\Exp{f^2(t_i)\left(\DeltaW\right)^2} + \label{eq:itois2}\\ 
					 &\phantom{{}=1} 2\sum_{i<j}\Exp{f(t_i)f(t_j) \DeltaW\DeltaW[j]}.\label{eq:itois3}
	\end{align}
	Where, (\ref{eq:itois3}):
	\begin{align*}
		\Exp{f(t_i)f(t_j) \DeltaW\DeltaW[j]} &= \Exp{\Exp{f(t_i)f(t_j) \DeltaW\DeltaW[j]|\salgF_{t_j}}}\\
			&= \Exp{f(t_i)f(t_j)\DeltaW\Exp{\DeltaW[j]|\salgF_{t_j}}}\\
			&= 0.
	\end{align*}
	
	We can rewrite (\ref{eq:itois1}) using only (\ref{eq:itois2}), i.e.,
	\begin{align*}
		\Exp{I(f)^2} &= \sum_{i=0}^{n-1}\Exp{f^2(t_i)\left(\DeltaW\right)^2}\\
		&= \sum_{i=0}^{n-1}\Exp{\Exp{f^2(t_i)\left(\DeltaW\right)^2|\salgF_{t_i}}} \\
		&= \sum_{i=0}^{n-1}\Exp{f^2(t_i)\Exp{\left(\DeltaW\right)^2|\salgF_{t_i}}} \\
		&= \sum_{i=0}^{n-1}\Exp{f^2(t_i)}\left(t_{i+1} - t_i\right) \\
		&= \int_0^t \Exp{f^2(s)} ds.
	\end{align*}
\end{proof}

\begin{remark}
	It\^o's integral as defined for $f\in\Mfam{a}{b}$ is a linear function, and indeed, an isometry since
	\begin{equation}
		\norm{I(f)}_{[a,b]} = \norm{f}_{[a, b]\times\Omega}.
	\end{equation}
	We can rewrite this last statement as
	\begin{equation}
		\Exp{\left(\int_0^t f dWs\right)} = \int_0^t\Exp{f^2(s)} ds = \Exp{\int_0^t f^2(s) ds}.
	\end{equation}	 
	
	Consequently, for any $f, g \in \Mfam{0}{t}$
	\begin{equation}
		\innerprod{I(f)}{I(g)}_{\Omega} = \innerprod{f}{g}_{\Omega\times[0, t]}.
	\end{equation}

To see why, we first note that $\innerprod{f}{g} = \int_0^t\Exp{f\cdot g}dt$. It follows that
\begin{align*}
	\innerprod{I(f)}{I(g)} &= \frac{1}{4}\left(\norm{I(f) + I(g)}^2 - \norm{I(f) - I(g)}^2\right)\\
						   &= \frac{1}{4}\left(\norm{I(f + g)}^2 - \norm{I(f - g)}^2\right)\\
						   &= \frac{1}{4}\left(\int_0^t \Exp{(f+g)^2}dt - \int_0^t \Exp{(f-g)^2}dt\right)\\
						   &= \frac{1}{4}\left(\int_0^t\Exp{f^2 + 2f\cdot g + g^2 - f^2 + 2f\cdot g - g^2} dt\right)\\
						   &= \int_0^t\Exp{f\cdot g} dt \\
						   &= \Exp{\int_0^t \left(f\cdot g\right) dt}\\
						   &= \innerprod{f}{g}.
\end{align*}
\end{remark}

%TODO: Add Proof
\begin{proposition}\label{prop:bounded_simple_borel}
	Let $f:[0, t]\to \RNums$ a Borel-measurable function such that $|f|\leq M$, and define $f_n:[0, t]\to \RNums$ as
	\begin{equation}
		f_n(\tau) := n\int_0^\tau e^{-n(\tau-s)}f(s) ds; \ 0 \leq \tau \leq t.
	\end{equation}
Then, $\{f_n\}$ is uniformly bounded by $M$ and $f_n \to f$ ($\mu$ a.e.) for every $\tau\in [0, t]$.
\end{proposition}

\begin{proposition}\label{prop:l2_convergence_ito_integral}
	The space $\Mfam{0}{t}$ is dense in $\Nfam{0}{t}$ under $L_2([a,b]\times\Omega)$. That is, for every $f\in\Nfam{0}{t}$, there exists a sequence $\{f_n\}_{n\geq 1} \in \Mfam{0}{t}$ such that
	\begin{equation}
		\Exp{\left(\int_0^t |f_n(s) - f(s)|dW_s\right)^2} \to 0.
	\end{equation}
	
\begin{proof}
We first note that 
\begin{equation}
	\Exp{\left(\int_0^t |f_n(s) - f(s)|dW_s\right)^2} = \Exp{\int_0^t\left|f_n(s) - f(s) \right|^2 ds} \to 0.
\end{equation}

\textbf{Step 1}: Continuous and bounded $f\in\Nfam{0}{t}$.\\
Let $g(\cdot, \omega)\in \Nfam{0}{t}$ continuous for each $\omega$. Then there exist a set $\{h_n\}_{n\geq 1}$ of simple processes in $\Mfam{0}{t}$ such that 
	\begin{equation}
		\Exp{\int_0^t\left(g - h_n\right)^2 ds}	\to 0.
	\end{equation}

Let $h_n(t, \omega) = \sum_{j=0}^{n-1}g(t_i)	\ind_{[t_i, t_{i+1}](t)}$. Then, $h_n$ is simple and,
\begin{equation}
  \lim_{n\to\infty} g - h_n = 0.
\end{equation}

Since $g - h_n$ converges to 0 (a.e.), the convergence is also in measure. Consequently, from the bounded convergence theorem we have that
\begin{equation}
  \lim_{n\to\infty} \int_0^t\left(g - h_n\right)^2 ds = 0 \ \forall \ \omega \in \Omega.
\end{equation}

Finally, by the dominated convergence theorem we see that
\begin{align*}
  \lim_{n\to\infty} \int_\Omega\left(\int_0^t\left(g - h_n\right)^2 ds\right)d\Pm &=  \int_\Omega \lim_{n\to\infty} \left(\int_0^t\left(g - h_n\right)^2 ds\right)d\Pm \\
  &= \Exp{\lim_{n\to\infty}\left(\int_0^t\left(g - h_n\right)^2 ds\right)} \\
  &= 0.
\end{align*}

\textbf{Step 2}: Bounded $f\in\Nfam{0}{t}$.\\
Let $f\in\Nfam{0}{t}$ be bounded i.e., there exists $M<\infty$ such that $|f(t, \omega) \leq M|$ for every $(t,\omega) \in [a,b]\times\Omega$. Then, there exists a sequence $\{f_n\}_{n\geq 1}$ of simple functions such that $f_n \to f$ in $L_2$.\\

By \ref{prop:bounded_simple_borel}, there exists $f_n$ such that $t\to f_n(t,\omega)$ is continuous for every $\omega\in\Omega$, $|f(t,\omega)|\leq M$, and $f_n(t,\Omega) \to f(t,\Omega)$. Since $f_n\to f$ a.e., then $f_n - f \to 0$ in measure, where we conclude by the bounded convergence theorem that
	\begin{equation}
		\Exp{\int_0^t(f_n - f)^2 ds} \to 0.
	\end{equation}

\textbf{Step 3}: Any $f\in\Nfam{0}{t}$.\\
For every $n\in\mathbb{N}$, define
	\begin{equation}
		f_n(t) = \begin{cases}
					f(t) & |f(t)|\leq n\\
					n 	 & f(t) > n \\
					-n   & f(t) < n
			     \end{cases}
	\end{equation}
It can be seen that $f_n\to f$. This implies a.e. convergence, and as a consequence, convergence in measure. Furthermore, $f_n$ is bounded by $f$ ($|f_n| \leq f$). The $L_2$ convergence follows from the dominated convergence.
\end{proof}
\end{proposition}

\begin{definition}[\textbf{It\^o's Integral for $f\in\Nfam{0}{t}$}]
	Let $f\in\Nfam{0}{t}$. By proposition \ref{prop:l2_convergence_ito_integral} there exists a sequence of simple processes $\{f_n\}_{n} \in \Mfam{0}{t}$ such that
	\begin{equation}
		\Exp{\int_0^t (f_n - f)^2 dt} \to 0.
	\end{equation}
	
	Then, the sequence $\{I(f_n)\}$ is a Cauchy sequence in $L_2\ProbSpace$ because
	\begin{align*}
		\Exp{(I(f_n) - I(f))^2} &= \Exp{\left|\int_0^t f_n dW - \int_0^t f dW\right|^2} \text{ (in $\ProbSpace$)} \\
								&= \Exp{\int_0^t(f_n - f)^2 ds} \text{ (in $([0,t]\times)\Omega,\mathscr B{([0,t])}\times\salgF, \lambda\times\Pm $)}.
	\end{align*}
	
	Therefore, there exists a random variable $I(f)\in L_2$ such that $I(f_n) \to I(f)$ in $L_2$. This limit is known as the \textbf{It\^o Integral}, and. we write:
	\begin{equation}
		I(f) := \int_0^t f(t, \omega) dW_t(\omega) = \lim_{n\to\infty}\int_0^t f_n(t,\omega) dW_t(\omega) \text{ (in $L_2$)}.
	\end{equation}
\end{definition}

\begin{proposition}[\textbf{Properties for $f$, $g$ $\in \Nfam{0}{t}$}]
	Let $f, g \in \Nfam{0}{t}$ then,
	\begin{equation}
		\Exp{\int_0^t f dW_s} = 0;
	\end{equation}
	
	\begin{equation}
		\Var{\int_0^t f dW_s} = \Exp{\left(\int_0^t f dW_s\right)} = \Exp{\int_0^t f^2 ds}\text{; and}
	\end{equation}
	
	\begin{equation}
		cov\left(\int_0^tfdW_s, \int_0^tgdW_s\right) = \int_0^t \Exp{f\cdot g} ds.
	\end{equation}
\end{proposition}

\begin{definition}[\textbf{Indefinte Integral}]
	Let $f\in \Nfam{0}{T}$, we define the indefinite It\^o integral
	\begin{equation}
		X(t) := \int_0^t f(s) dW_s \ \forall \ t\in[0, T].
	\end{equation}
\end{definition}

\begin{proposition}
	Let $f\in\Nfam{0}{T}$ and $X(t)$ an indefinite integral then,
	\begin{enumerate}
		\item $X(\cdot)$ is adapted to $\salgF$, i.e., $X(t)$ is $\salgF_t$-measurable for all $t\in[0, T]$; \label{it:adapted-int}
		\item $X(t)$ is an $L_2$ process and a $\salgF_t$-martingale
	\end{enumerate}
\end{proposition}

%TODO: Complete proof
\begin{proof}
\end{proof}


%TODO: proof??
\begin{theorem}
	Let $f\in\Nfam{0}{T}$. There exists a $t$-continuous version of
	\begin{equation}
		\int_0^t f(s,\omega) dW_s(\omega) \ 0\leq t \leq T.
	\end{equation}
I.e., there exists a $t$-continuous stochastic process $Y_t$ defined over $\ProbSpace$ such that
\begin{equation}
	\Pm\left[Y_t = \int_0^tf(s,\omega) dW_s(\omega)\right] = 1 \ \forall \ 0\leq t \leq T.
\end{equation}
\end{theorem}

\section{Extensions of It\^o's Integral}
\begin{definition}
	Let $W(\cdot) := \{W_t : t\geq 0\}$ a Brownian motion process over $\ProbSpace$ and let $\mathscr{G}$, a family of $\salg$s where
	\begin{enumerate}
		\item $\mathscr{G}(s) \subseteq \mathscr{G}(t)$ for all $0\leq s \leq t$;
		\item $W(\cdot)$ is adapted to $\mathscr{G}(\cdot)$, i.e.,
		\item For all $f\geq 0$ and $h > 0$, $W_{t+h} - W_t$ is independent of $\mathscr{G}(t)$.
	\end{enumerate}
\end{definition}

\section{It\^o's Formula}
\begin{definition}[\textbf{It\^o Process}]
	let $W_t$ a standard Brownian motion on $\ProbSpace$. We define the It\^o process $X(t)$ over $\ProbSpace$ as
	\begin{equation}
		X(t) := \int_0^t\mu(s,\omega) ds  + \int_0^t\sigma(s,\omega) dW_s
	\end{equation}

\end{definition}
\section{Stochastic Differential Equations}
\end{document}